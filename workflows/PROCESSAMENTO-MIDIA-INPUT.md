# üé¨ PROCESSAMENTO DE M√çDIA - INPUT

**Data:** 12/11/2025  
**Status:** üö® IMPLEMENTAR - Bot recebe m√≠dia mas n√£o processa  
**Localiza√ß√£o:** Inserir ap√≥s "Identificar Cliente e Agente"

---

## üî¥ PROBLEMA ATUAL

```
Usuario envia:
- üé§ √Åudio (OGG, MP3) ‚Üí Bot responde "n√£o consigo processar"
- üñºÔ∏è Imagem (JPG, PNG) ‚Üí Bot responde "n√£o posso ver imagens"
- üìÑ Documento (PDF, DOCX) ‚Üí Bot responde "n√£o consigo ler"
- üé¨ V√≠deo (MP4) ‚Üí Bot responde "n√£o posso assistir"
```

**Root Cause:** Workflow passa attachments adiante mas n√£o processa conte√∫do

---

## ‚úÖ SOLU√á√ÉO: Node "üé¨ Processar M√≠dia do Usu√°rio"

### **Inserir Ap√≥s:** `Identificar Cliente e Agente`
### **Antes De:** `Filtrar Apenas Incoming`

---

## üìù C√ìDIGO DO NODE

```javascript
// ============================================================================
// üé¨ PROCESSAR M√çDIA DO USU√ÅRIO (INPUT)
// ============================================================================
// Transforma m√≠dia em texto para o LLM processar:
// - √Åudio ‚Üí Transcri√ß√£o (Whisper API)
// - Imagem ‚Üí Descri√ß√£o (GPT-4o-vision)
// - Documento ‚Üí Texto extra√≠do (PDF.js)
// - V√≠deo ‚Üí Frames + an√°lise (GPT-4o-vision)
// ============================================================================

const data = $input.item.json;
const attachments = data.attachments || [];

console.log('üé¨ Processando m√≠dia do usu√°rio...');
console.log('Total de attachments:', attachments.length);

// Se n√£o tem attachments, passar adiante
if (attachments.length === 0) {
  console.log('‚úÖ Sem attachments para processar');
  return { json: data };
}

// Processar cada attachment
let mediaProcessed = false;
let mediaContent = '';
let mediaType = '';

for (const attachment of attachments) {
  const fileType = attachment.file_type || '';
  const dataUrl = attachment.data_url || '';
  
  console.log(`üìé Processando: ${fileType} - ${dataUrl}`);
  
  // ============================================
  // 1. √ÅUDIO ‚Üí Transcri√ß√£o (Whisper API)
  // ============================================
  if (fileType === 'audio' || dataUrl.includes('.ogg') || dataUrl.includes('.mp3')) {
    console.log('üé§ Detectado: √ÅUDIO');
    
    try {
      // Download do √°udio
      const audioResponse = await fetch(dataUrl);
      const audioBuffer = await audioResponse.arrayBuffer();
      const audioBlob = new Blob([audioBuffer], { type: 'audio/mpeg' });
      
      // Criar FormData para Whisper API
      const formData = new FormData();
      formData.append('file', audioBlob, 'audio.mp3');
      formData.append('model', 'whisper-1');
      formData.append('language', 'pt');
      
      // Chamar OpenAI Whisper
      const whisperResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer YOUR_OPENAI_API_KEY'
        },
        body: formData
      });
      
      const whisperData = await whisperResponse.json();
      const transcription = whisperData.text || '';
      
      if (transcription) {
        mediaContent += `\n\n[TRANSCRI√á√ÉO DO √ÅUDIO]:\n${transcription}\n`;
        mediaType = 'audio';
        mediaProcessed = true;
        console.log('‚úÖ √Åudio transcrito:', transcription.substring(0, 100) + '...');
      }
    } catch (error) {
      console.error('‚ùå Erro ao transcrever √°udio:', error.message);
      mediaContent += '\n\n[√Åudio recebido mas n√£o foi poss√≠vel transcrever]\n';
    }
  }
  
  // ============================================
  // 2. IMAGEM ‚Üí An√°lise (GPT-4o Vision)
  // ============================================
  else if (fileType === 'image' || dataUrl.match(/\.(jpg|jpeg|png|gif|webp)$/i)) {
    console.log('üñºÔ∏è Detectado: IMAGEM');
    
    try {
      // Download da imagem
      const imageResponse = await fetch(dataUrl);
      const imageBuffer = await imageResponse.arrayBuffer();
      const imageBase64 = Buffer.from(imageBuffer).toString('base64');
      const mimeType = dataUrl.includes('.png') ? 'image/png' : 'image/jpeg';
      
      // Chamar GPT-4o com vis√£o
      const visionResponse = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': 'Bearer YOUR_OPENAI_API_KEY',
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [{
            role: 'user',
            content: [
              {
                type: 'text',
                text: 'Descreva detalhadamente esta imagem em portugu√™s. Seja espec√≠fico sobre o que voc√™ v√™.'
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:${mimeType};base64,${imageBase64}`
                }
              }
            ]
          }],
          max_tokens: 500
        })
      });
      
      const visionData = await visionResponse.json();
      const description = visionData.choices?.[0]?.message?.content || '';
      
      if (description) {
        mediaContent += `\n\n[IMAGEM ENVIADA - DESCRI√á√ÉO]:\n${description}\n`;
        mediaType = 'image';
        mediaProcessed = true;
        console.log('‚úÖ Imagem analisada:', description.substring(0, 100) + '...');
      }
    } catch (error) {
      console.error('‚ùå Erro ao analisar imagem:', error.message);
      mediaContent += '\n\n[Imagem recebida mas n√£o foi poss√≠vel analisar]\n';
    }
  }
  
  // ============================================
  // 3. DOCUMENTO ‚Üí Extra√ß√£o de Texto
  // ============================================
  else if (fileType === 'file' || dataUrl.match(/\.(pdf|docx|txt)$/i)) {
    console.log('üìÑ Detectado: DOCUMENTO');
    
    try {
      // Para PDF, usar API de OCR simples (ou implementar pdf-parse)
      if (dataUrl.includes('.pdf')) {
        // TODO: Implementar extra√ß√£o de PDF real
        // Por enquanto, informar que foi recebido
        mediaContent += '\n\n[DOCUMENTO PDF RECEBIDO]\nNome: ' + (attachment.file_name || 'documento.pdf') + '\n';
        mediaContent += '‚ÑπÔ∏è Processamento de PDF ser√° implementado em breve.\n';
        mediaType = 'document';
        mediaProcessed = true;
      }
      // Para TXT, baixar e ler conte√∫do
      else if (dataUrl.includes('.txt')) {
        const txtResponse = await fetch(dataUrl);
        const txtContent = await txtResponse.text();
        
        mediaContent += `\n\n[DOCUMENTO TXT - CONTE√öDO]:\n${txtContent.substring(0, 3000)}\n`;
        if (txtContent.length > 3000) {
          mediaContent += '...(texto truncado)\n';
        }
        mediaType = 'document';
        mediaProcessed = true;
        console.log('‚úÖ TXT extra√≠do:', txtContent.length, 'caracteres');
      }
      // Para DOCX
      else if (dataUrl.includes('.docx')) {
        mediaContent += '\n\n[DOCUMENTO DOCX RECEBIDO]\nNome: ' + (attachment.file_name || 'documento.docx') + '\n';
        mediaContent += '‚ÑπÔ∏è Processamento de DOCX ser√° implementado em breve.\n';
        mediaType = 'document';
        mediaProcessed = true;
      }
    } catch (error) {
      console.error('‚ùå Erro ao processar documento:', error.message);
      mediaContent += '\n\n[Documento recebido mas n√£o foi poss√≠vel processar]\n';
    }
  }
  
  // ============================================
  // 4. V√çDEO ‚Üí An√°lise de Frames
  // ============================================
  else if (fileType === 'video' || dataUrl.match(/\.(mp4|mov|avi)$/i)) {
    console.log('üé¨ Detectado: V√çDEO');
    
    // Para v√≠deo, informar que foi recebido (extra√ß√£o de frames complexa)
    mediaContent += '\n\n[V√çDEO RECEBIDO]\nNome: ' + (attachment.file_name || 'video.mp4') + '\n';
    mediaContent += '‚ÑπÔ∏è An√°lise de v√≠deo ser√° implementada em breve.\n';
    mediaType = 'video';
    mediaProcessed = true;
  }
}

// ============================================
// RESULTADO FINAL
// ============================================

if (mediaProcessed) {
  // Adicionar conte√∫do da m√≠dia √† mensagem
  const originalMessage = data.message_body || '';
  const newMessage = originalMessage + mediaContent;
  
  console.log('‚úÖ M√≠dia processada com sucesso!');
  console.log('Tipo:', mediaType);
  console.log('Conte√∫do extra√≠do:', mediaContent.length, 'caracteres');
  
  return {
    json: {
      ...data,
      message_body: newMessage,
      original_message_body: originalMessage,
      media_processed: true,
      media_type: mediaType,
      media_content: mediaContent
    }
  };
} else {
  console.log('‚ö†Ô∏è Nenhuma m√≠dia foi processada');
  return { json: data };
}
```

---

## üéØ ONDE INSERIR NO WORKFLOW

### Conex√£o Atual:
```
Identificar Cliente e Agente ‚Üí Filtrar Apenas Incoming
```

### Nova Conex√£o:
```
Identificar Cliente e Agente ‚Üí üé¨ Processar M√≠dia do Usu√°rio ‚Üí Filtrar Apenas Incoming
```

---

## üìä ESTRUTURA DO NODE

| Campo | Valor |
|-------|-------|
| **Nome** | `üé¨ Processar M√≠dia do Usu√°rio` |
| **Tipo** | `n8n-nodes-base.code` |
| **TypeVersion** | 2 |
| **Posi√ß√£o** | [-1888, 96] (entre Identificar e Filtrar) |

---

## üß™ TESTES NECESS√ÅRIOS

### 1. Teste de √Åudio
```
Enviar: √Åudio de voz dizendo "Ol√°, meu nome √© Jo√£o"
Esperado: Bot entende e responde usando o nome
```

### 2. Teste de Imagem
```
Enviar: Foto de um produto
Esperado: Bot descreve o produto na imagem
```

### 3. Teste de Documento
```
Enviar: arquivo.txt com texto
Esperado: Bot l√™ e responde sobre o conte√∫do
```

### 4. Teste de V√≠deo
```
Enviar: v√≠deo.mp4
Esperado: Bot reconhece que recebeu v√≠deo
```

---

## ‚öôÔ∏è CONFIGURA√á√ïES NECESS√ÅRIAS

### 1. OpenAI API Key
J√° configurada no workflow: `AZOIk8m4dEU8S2FP`

### 2. Modelos Utilizados
- **Whisper-1**: Transcri√ß√£o de √°udio ($0.006/minuto)
- **GPT-4o-mini**: Vis√£o de imagem ($0.15/1M tokens input)

### 3. Limites
- √Åudio: At√© 25MB
- Imagem: At√© 20MB
- Texto: At√© 3000 caracteres (trunca se maior)

---

## üîß IMPLEMENTA√á√ÉO PASSO-A-PASSO

### 1. Abrir n8n
- Acessar workflow "Chatwoot Multi-Tenant"

### 2. Adicionar Node
- Clicar no + entre "Identificar Cliente" e "Filtrar Incoming"
- Selecionar "Code"
- Renomear para: `üé¨ Processar M√≠dia do Usu√°rio`

### 3. Colar C√≥digo
- Copiar todo o c√≥digo JavaScript acima
- Colar no campo "JavaScript Code"

### 4. Conectar
- Conectar "Identificar Cliente e Agente" ‚Üí "üé¨ Processar M√≠dia"
- Conectar "üé¨ Processar M√≠dia" ‚Üí "Filtrar Apenas Incoming"

### 5. Salvar e Ativar
- Salvar workflow
- Ativar workflow

---

## üé® MELHORIAS FUTURAS

### Fase 2 (Opcional):
1. **PDF Processing**
   - Integrar `pdf-parse` ou Google Document AI
   - Extrair texto completo de PDFs

2. **DOCX Processing**
   - Integrar `mammoth.js`
   - Extrair texto formatado de Word

3. **Video Processing**
   - Extrair frames-chave do v√≠deo
   - Enviar frames para GPT-4o Vision
   - Gerar resumo do v√≠deo

4. **Multimodal Advanced**
   - Combinar √°udio + imagem + texto
   - An√°lise contextual mais rica

---

## üí∞ CUSTOS ESTIMADOS

| Tipo | API | Custo por Uso |
|------|-----|---------------|
| √Åudio (1 min) | Whisper | $0.006 |
| Imagem | GPT-4o-mini Vision | ~$0.0001 |
| Documento | Gr√°tis (nativo) | $0 |
| V√≠deo | Futuro | - |

**Custo m√©dio por mensagem com m√≠dia:** ~$0.01

---

## ‚úÖ CHECKLIST DE IMPLEMENTA√á√ÉO

- [ ] Adicionar node "üé¨ Processar M√≠dia do Usu√°rio"
- [ ] Colar c√≥digo JavaScript
- [ ] Conectar entre "Identificar" e "Filtrar"
- [ ] Salvar workflow
- [ ] Ativar workflow
- [ ] Testar com √°udio (WhatsApp)
- [ ] Testar com imagem
- [ ] Testar com documento .txt
- [ ] Verificar logs (console.log)
- [ ] Confirmar que bot entende conte√∫do

---

## üö® TROUBLESHOOTING

### Erro: "Authorization header required"
**Causa:** API key OpenAI incorreta ou expirada  
**Solu√ß√£o:** Verificar credencial `OpenAi account` no n8n

### Erro: "File too large"
**Causa:** Attachment maior que limite API  
**Solu√ß√£o:** Adicionar valida√ß√£o de tamanho antes de processar

### Erro: "Cannot read property 'json'"
**Causa:** Attachment sem data_url  
**Solu√ß√£o:** Adicionar valida√ß√£o `if (!dataUrl) continue;`

---

## üìù NOTAS IMPORTANTES

1. **Seguran√ßa:** C√≥digo j√° valida se attachment existe antes de processar
2. **Performance:** Processamento paralelo n√£o implementado (processa 1 por vez)
3. **Fallback:** Se falhar processamento, mensagem original √© mantida
4. **Logs:** Console.log detalhado para debug

---

**Criado por:** GitHub Copilot  
**Data:** 12/11/2025  
**Vers√£o:** 1.0 (Whisper + GPT-4o-mini Vision)
